{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a07fd19ef67c22c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:09:32.308413Z",
     "start_time": "2025-11-27T17:09:28.204051Z"
    }
   },
   "outputs": [],
   "source": [
    "# load movie review dataset(with NER Metadata) - size = 7816\n",
    "\n",
    "import pandas as pd\n",
    "matched_reviews = pd.read_csv(\"clean_dataset.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "print(matched_reviews.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a8f7600880056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:09:45.518065Z",
     "start_time": "2025-11-27T17:09:32.324395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline Classification Models (Logistic regression and SVM) without NER Metadata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Copy data for modeling\n",
    "df = matched_reviews.copy()\n",
    "\n",
    "# Ensure movie review text is string\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20_000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4afe24c4746605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:09:52.635077Z",
     "start_time": "2025-11-27T17:09:52.456450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Logistic Regression (Without NER Metadata)====\n",
      "Accuracy: 0.760230179028133\n",
      "F1 Score: 0.8500599760095962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.27      0.40       459\n",
      "           1       0.76      0.96      0.85      1105\n",
      "\n",
      "    accuracy                           0.76      1564\n",
      "   macro avg       0.76      0.62      0.63      1564\n",
      "weighted avg       0.76      0.76      0.72      1564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model (Without NER Metadata)\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_lr = log_reg.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Logistic Regression (Without NER Metadata)====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_lr))\n",
    "print(classification_report(y_test, pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b097d143e22dde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:09:57.505494Z",
     "start_time": "2025-11-27T17:09:57.467666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Linear SVM (Without NER Metadata) ====\n",
      "Accuracy: 0.7736572890025576\n",
      "F1 Score: 0.8493617021276596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.46      0.54       459\n",
      "           1       0.80      0.90      0.85      1105\n",
      "\n",
      "    accuracy                           0.77      1564\n",
      "   macro avg       0.73      0.68      0.70      1564\n",
      "weighted avg       0.76      0.77      0.76      1564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM Model Without NER Metadata\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_svm = svm_clf.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Linear SVM (Without NER Metadata) ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10057214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:10:05.974904Z",
     "start_time": "2025-11-27T17:10:02.324136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline Classification Models (Logistic regression and SVM) with NER Metadata\n",
    "\n",
    "from textblob import TextBlob \n",
    "\n",
    "# A function to compute entity features eg. count the number of time actors/directors were mentioned, entity sentiment, etc\n",
    "def compute_entity_features(row):\n",
    "\n",
    "    # actors/directors are lists, not strings\n",
    "    actors = row.get(\"actors\", [])\n",
    "    directors = row.get(\"directors\", [])\n",
    "\n",
    "    num_actors = len(actors)\n",
    "    num_directors = len(directors)\n",
    "\n",
    "    # review text to lowercase\n",
    "    text = row[\"text\"].lower()\n",
    "\n",
    "    # Count actor mentions\n",
    "    actor_mentions = 0\n",
    "    for a in actors:\n",
    "        actor_mentions += text.count(a.lower())\n",
    "\n",
    "    # Count director mentions\n",
    "    director_mentions = 0\n",
    "    for d in directors:\n",
    "        director_mentions += text.count(d.lower())\n",
    "\n",
    "    # Sentiment toward entity names\n",
    "    entity_tokens = actors + directors\n",
    "    entity_sentiment = 0\n",
    "\n",
    "    if entity_tokens:\n",
    "        combined = \" \".join(entity_tokens)\n",
    "        try:\n",
    "            entity_sentiment = TextBlob(combined).sentiment.polarity\n",
    "        except:\n",
    "            entity_sentiment = 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"num_actors\": num_actors,\n",
    "        \"num_directors\": num_directors,\n",
    "        \"actor_mentions\": actor_mentions,\n",
    "        \"director_mentions\": director_mentions,\n",
    "        \"entity_sentiment\": entity_sentiment\n",
    "    })\n",
    "\n",
    "\n",
    "# Compute entity features\n",
    "entity_features = matched_reviews.apply(compute_entity_features, axis=1)\n",
    "full_df = pd.concat([matched_reviews, entity_features], axis=1)\n",
    "# print(full_df.head()) - you can optionally run this to check to see new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021aeaf1246e003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:10:09.036019Z",
     "start_time": "2025-11-27T17:10:08.722711Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split BEFORE vectorization\n",
    "X_text_raw = full_df[\"text\"]\n",
    "X_entity = full_df[[\n",
    "    \"num_actors\", \"num_directors\",\n",
    "    \"actor_mentions\", \"director_mentions\",\n",
    "    \"entity_sentiment\"\n",
    "]].fillna(0)\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Train-test split on raw data\n",
    "X_text_train, X_text_test, X_entity_train, X_entity_test, y_train, y_test = train_test_split(\n",
    "    X_text_raw, X_entity, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now fit TF-IDF only on training text\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_text = tfidf.fit_transform(X_text_train)  # Learn from train only\n",
    "X_test_text = tfidf.transform(X_text_test)        # Apply to test\n",
    "\n",
    "# Scale entity features (fit on train, transform both)\n",
    "scaler = StandardScaler(with_mean=False)  # Sparse-compatible\n",
    "X_entity_train_scaled = scaler.fit_transform(X_entity_train.values)\n",
    "X_entity_test_scaled = scaler.transform(X_entity_test.values)\n",
    "\n",
    "# Combine features\n",
    "X_train = hstack([X_train_text, X_entity_train_scaled])\n",
    "X_test = hstack([X_test_text, X_entity_test_scaled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9b511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:10:13.342962Z",
     "start_time": "2025-11-27T17:10:13.176873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware Logistic Regression ====\n",
      "Accuracy: 0.7794117647058824\n",
      "F1 Score: 0.8570244508910071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.40      0.52       459\n",
      "           1       0.79      0.94      0.86      1105\n",
      "\n",
      "    accuracy                           0.78      1564\n",
      "   macro avg       0.76      0.67      0.69      1564\n",
      "weighted avg       0.77      0.78      0.76      1564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with NER features\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=500)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Logistic Regression (with NER Metadata) ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_log))\n",
    "print(classification_report(y_test, pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e89465c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T18:28:43.812115Z",
     "start_time": "2025-11-27T18:28:43.613426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== SVM (with NER Metadata) ====\n",
      "Accuracy: 0.7896419437340153\n",
      "F1 Score: 0.8572668112798265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.54      0.60       459\n",
      "           1       0.82      0.89      0.86      1105\n",
      "\n",
      "    accuracy                           0.79      1564\n",
      "   macro avg       0.75      0.72      0.73      1564\n",
      "weighted avg       0.78      0.79      0.78      1564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM with NER features\n",
    "\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"==== SVM (with NER Metadata) ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeac4338fb55900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:11:12.760065Z",
     "start_time": "2025-11-27T17:10:23.010810Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Map: 100%|██████████| 6252/6252 [00:00<00:00, 26221.92 examples/s]\n",
      "Map: 100%|██████████| 1564/1564 [00:00<00:00, 19078.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  \\\n",
      "0     steve mcqueen provided a thrilling motorcycle ...   \n",
      "1     liza minnelli and joel gray won oscars for the...   \n",
      "2     what is that tom hanks and julia roberts movie...   \n",
      "3     what is the movie making fun of macgyver by re...   \n",
      "4     i am thinking of an animated film based on a c...   \n",
      "...                                                 ...   \n",
      "7811  you see this 1965 musical masterpiece regularl...   \n",
      "7812  young traveler allan gray discovers evidence o...   \n",
      "7813  yul bryner recreated his broadway role in this...   \n",
      "7814  yul brynner won an oscar for his role in this ...   \n",
      "7815  zac efron is a soldier searching for the woman...   \n",
      "\n",
      "                              actors                   directors  label  \\\n",
      "0                  ['steve mcqueen']                          []      1   \n",
      "1     ['liza minnelli', 'joel gray']                          []      1   \n",
      "2     ['tom hanks', 'julia roberts']                          []      0   \n",
      "3                                 []                          []      1   \n",
      "4                                 []                          []      1   \n",
      "...                              ...                         ...    ...   \n",
      "7811                              []                          []      1   \n",
      "7812                              []                          []      1   \n",
      "7813                  ['yul bryner']                          []      1   \n",
      "7814                 ['yul brynner']  ['rogers and hammerstein']      1   \n",
      "7815                   ['zac efron']                          []      1   \n",
      "\n",
      "      num_actors  num_directors  actor_mentions  director_mentions  \\\n",
      "0           17.0            2.0            94.0                0.0   \n",
      "1           30.0            2.0           238.0                0.0   \n",
      "2           30.0            2.0           238.0                0.0   \n",
      "3            2.0            2.0             0.0                0.0   \n",
      "4            2.0            2.0             0.0                0.0   \n",
      "...          ...            ...             ...                ...   \n",
      "7811         2.0            2.0             0.0                0.0   \n",
      "7812         2.0            2.0             0.0                0.0   \n",
      "7813        14.0            2.0            60.0                0.0   \n",
      "7814        15.0           26.0            59.0              126.0   \n",
      "7815        13.0            2.0            76.0                0.0   \n",
      "\n",
      "      entity_sentiment  \n",
      "0                  0.0  \n",
      "1                  0.0  \n",
      "2                  0.0  \n",
      "3                  0.0  \n",
      "4                  0.0  \n",
      "...                ...  \n",
      "7811               0.0  \n",
      "7812               0.0  \n",
      "7813               0.0  \n",
      "7814               0.0  \n",
      "7815               0.0  \n",
      "\n",
      "[7816 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# DistilBERT Model with NER Metadata\n",
    "\n",
    "from transformers import DistilBertTokenizerFast\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Load data\n",
    "entity_cols = [\"num_actors\", \"num_directors\",\n",
    "               \"actor_mentions\", \"director_mentions\", \"entity_sentiment\"]\n",
    "\n",
    "df = full_df[[\"text\", \"label\",\"actors\",\"directors\"] + entity_cols].dropna()\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "MAX_LEN = 128   # MUCH FASTER (cut 256 → 128)\n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    encoded = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=False,       # dynamic padding enabled later\n",
    "    )\n",
    "    # add entity features\n",
    "    for col in entity_cols:\n",
    "        encoded[col] = batch[col]\n",
    "    return encoded\n",
    "\n",
    "# Remove original columns except what we return\n",
    "cols_to_keep = [\"input_ids\", \"attention_mask\", \"label\"] + entity_cols\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    remove_columns=[c for c in train_ds.column_names if c not in cols_to_keep]\n",
    ")\n",
    "\n",
    "test_ds = test_ds.map(\n",
    "    tokenize_batch,\n",
    "    batched=True,\n",
    "    remove_columns=[c for c in test_ds.column_names if c not in cols_to_keep]\n",
    ")\n",
    "\n",
    "\n",
    "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "test_ds = test_ds.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914d855a44c698d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:11:19.749205Z",
     "start_time": "2025-11-27T17:11:18.863109Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize entity features\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from transformers import TrainingArguments, Trainer, DistilBertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[entity_cols] = scaler.fit_transform(df[entity_cols])\n",
    "\n",
    "# Dynamic padding - Faster GPU and less memory\n",
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "class DistilBertWithEntities(nn.Module):\n",
    "    def __init__(self, num_labels, entity_dim=6):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(768 + entity_dim, num_labels)\n",
    "\n",
    "    # DistilBERT forward methold\n",
    "    def forward(self,input_ids=None,attention_mask=None,labels=None,num_actors=None,num_directors=None,actor_mentions=None,director_mentions=None,\n",
    "        entity_sentiment=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0]  # CLS token\n",
    "\n",
    "        # Stack entity features\n",
    "        entity_tensors = [\n",
    "            num_actors.unsqueeze(1).float(),\n",
    "            num_directors.unsqueeze(1).float(),\n",
    "            actor_mentions.unsqueeze(1).float(),\n",
    "            director_mentions.unsqueeze(1).float(),\n",
    "            entity_sentiment.unsqueeze(1).float(),\n",
    "        ]\n",
    "        entity_tensor = torch.cat(entity_tensors, dim=1)\n",
    "\n",
    "        # Combine text + entity features\n",
    "        combined = torch.cat((pooled_output, entity_tensor), dim=1)\n",
    "        combined = self.dropout(combined)\n",
    "        logits = self.fc(combined)\n",
    "\n",
    "        # Loss with optional class weights\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            class_counts = torch.bincount(labels)\n",
    "            class_weights = (1.0 / class_counts.float()).to(logits.device)\n",
    "            loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "        return {\"loss\": loss, \"logits\": logits}\n",
    "\n",
    "num_labels = df[\"label\"].nunique()\n",
    "model = DistilBertWithEntities(num_labels, entity_dim=len(entity_cols))\n",
    "\n",
    "# Training Arguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-entity-improved\",\n",
    "\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "\n",
    "    gradient_accumulation_steps=2,   # effective batch = 32\n",
    "    learning_rate=3e-5,\n",
    "\n",
    "    num_train_epochs=2,\n",
    "    save_strategy=\"epoch\",\n",
    "\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    dataloader_num_workers=4,\n",
    "    dataloader_pin_memory=True,\n",
    "\n",
    "    logging_steps=100,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8b78471916c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:26:07.259329Z",
     "start_time": "2025-11-27T17:11:27.649785Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='392' max='392' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [392/392 14:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.825400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.506400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.335800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=392, training_loss=0.4936037890765132, metrics={'train_runtime': 879.3719, 'train_samples_per_second': 14.219, 'train_steps_per_second': 0.446, 'total_flos': 0.0, 'train_loss': 0.4936037890765132, 'epoch': 2.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5cc2f7ad0695d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:27:01.052244Z",
     "start_time": "2025-11-27T17:26:13.551875Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.35099494457244873,\n",
       " 'eval_runtime': 47.4878,\n",
       " 'eval_samples_per_second': 32.935,\n",
       " 'eval_steps_per_second': 1.032,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "\n",
    "\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de848a657a7806ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:27:55.101886Z",
     "start_time": "2025-11-27T17:27:07.822741Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity Aware - DistilBERT Evaluation ====\n",
      "Accuracy: 0.8714833759590793\n",
      "F1 Score: 0.874136443853217\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80       459\n",
      "           1       0.94      0.87      0.91      1105\n",
      "\n",
      "    accuracy                           0.87      1564\n",
      "   macro avg       0.84      0.87      0.85      1564\n",
      "weighted avg       0.88      0.87      0.87      1564\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from trainer\n",
    "\n",
    "predictions = trainer.predict(test_ds)\n",
    "\n",
    "# Extract logits and labels\n",
    "preds = predictions.predictions\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Convert logits to predicted class indices\n",
    "preds = preds.argmax(axis=-1)\n",
    "\n",
    "acc = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds, average='weighted')  # or 'macro' if you prefer\n",
    "\n",
    "print(\"==== DistilBERT Evaluation (With NER Metadata) ====\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81fbe8e6f333df3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:28:25.299822Z",
     "start_time": "2025-11-27T17:28:23.509206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bias Evaluation - Token Level Attribution Score\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "# Function to compute attributions for tokens\n",
    "def attribute_tokens(text, entity_values, tokenizer, model, max_len=128, target_class=1):\n",
    "\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "\n",
    "    input_ids = inputs[\"input_ids\"].long()\n",
    "    attention_mask = inputs[\"attention_mask\"].long()\n",
    "\n",
    "    # Entity features\n",
    "    entity_tensor = torch.tensor(entity_values).unsqueeze(0).float()\n",
    "\n",
    "    # Convert input_ids to embeddings\n",
    "    embeddings = model.bert.embeddings(input_ids)  # shape: (1, seq_len, 768)\n",
    "\n",
    "    # Wrap model for Captum  function\n",
    "    def model_forward(embeddings, attention_mask, entity_tensor):\n",
    "\n",
    "        # Pass embeddings directly into DistilBERT\n",
    "        outputs = model.bert(\n",
    "            inputs_embeds=embeddings,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        pooled = outputs.last_hidden_state[:, 0]\n",
    "\n",
    "        # Entity features\n",
    "        entity_feat = torch.cat([\n",
    "            entity_tensor[:, 0].unsqueeze(1),\n",
    "            entity_tensor[:, 1].unsqueeze(1),\n",
    "            entity_tensor[:, 2].unsqueeze(1),\n",
    "            entity_tensor[:, 3].unsqueeze(1),\n",
    "            entity_tensor[:, 4].unsqueeze(1),\n",
    "        ], dim=1)\n",
    "\n",
    "        combined = torch.cat((pooled, entity_feat), dim=1)\n",
    "        combined = model.dropout(combined)\n",
    "        logits = model.fc(combined)\n",
    "\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        return probs[:, target_class]\n",
    "\n",
    "    # Integrated Gradients \n",
    "    ig = IntegratedGradients(model_forward)\n",
    "\n",
    "    attributions, delta = ig.attribute(\n",
    "        embeddings,\n",
    "        target=None,\n",
    "        additional_forward_args=(attention_mask, entity_tensor),\n",
    "        n_steps=50,\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "\n",
    "    # Convert attributions to token-level vector\n",
    "    token_attributions = attributions.sum(dim=-1).squeeze(0).detach().numpy()\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    return tokens, token_attributions, float(delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e878c432bd8827a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T18:34:00.670727Z",
     "start_time": "2025-11-27T18:33:59.395858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Level Attribution Score\n",
      " Review Text: arnold schwarzenegger s mission to mars gets a bit wacky when he does n t know if what he remembers actually happened or were implanted memories\n",
      "[CLS]: -0.0004\n",
      "arnold: -0.0054\n",
      "schwarz: -0.0111\n",
      "##ene: -0.0090\n",
      "##gger: -0.0153\n",
      "s: -0.0071\n",
      "mission: 0.0068\n",
      "to: -0.0103\n",
      "mars: -0.0096\n",
      "gets: -0.0215\n",
      "a: -0.0368\n",
      "bit: -0.0180\n",
      "wa: -0.0039\n",
      "##cky: -0.0151\n",
      "when: -0.0279\n",
      "he: -0.0103\n",
      "does: -0.0247\n",
      "n: -0.0163\n",
      "t: -0.0307\n",
      "know: -0.0218\n",
      "if: -0.0368\n",
      "what: -0.0240\n",
      "he: -0.0056\n",
      "remembers: -0.0013\n",
      "actually: -0.0182\n",
      "happened: -0.0094\n",
      "or: -0.0209\n",
      "were: -0.0393\n",
      "implant: -0.0137\n",
      "##ed: -0.0232\n",
      "memories: -0.0109\n",
      "[SEP]: -0.0706\n"
     ]
    }
   ],
   "source": [
    "review_row = full_df.iloc[2006]\n",
    "review_text = review_row['text']\n",
    "print(\"Token Level Attribution Score\")\n",
    "print(\" Review Text: \" +review_text)\n",
    "\n",
    "entity_features = [\n",
    "    review_row['num_actors'],\n",
    "    review_row['num_directors'],\n",
    "    review_row['actor_mentions'],\n",
    "    review_row['director_mentions'],\n",
    "    review_row['entity_sentiment'],\n",
    "]\n",
    "\n",
    "tokens, atts, delta = attribute_tokens(review_text, entity_features, tokenizer, model)\n",
    "\n",
    "for tok, score in zip(tokens, atts):\n",
    "    print(f\"{tok}: {score:.4f}\")\n",
    "\n",
    "# For example, take a review with arnold schwarzenegger as actor (56, 2006)\n",
    "# First result: \n",
    "# arnold: 0.0131\n",
    "# schwarz: -0.0075\n",
    "\n",
    "# Second result:\n",
    "#  arnold: -0.0054\n",
    "# schwarz: -0.0111\n",
    "\n",
    "# Actor - adam sandler (285, 517, 574, 726, 842, 1239, 1265, 1404, 1525, 1699, 1872, 1960, 1961, 2582, 2595, 2646, 2694, 3661, 3693, 3756, 3848,\n",
    "# 4010, 4236, 4246, 4286)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103ff11f17c41bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T17:37:30.105087Z",
     "start_time": "2025-11-27T17:37:29.957858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>sentiment_skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaaron johnson</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aang</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron sorkin</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.765614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adam elliot</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adam sandler</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.515614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>zach snyder</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.765614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>zachary gordon</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>zachary levi</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>zack galifianakis</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>zack snyder</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>677 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entity  pos_rate  num_reviews  sentiment_skew\n",
       "0       aaaron johnson      1.00            1        0.234386\n",
       "1                 aang      1.00            1        0.234386\n",
       "2         aaron sorkin      0.00            1       -0.765614\n",
       "3          adam elliot      1.00            2        0.234386\n",
       "4         adam sandler      0.25            4       -0.515614\n",
       "..                 ...       ...          ...             ...\n",
       "672        zach snyder      0.00            1       -0.765614\n",
       "673     zachary gordon      1.00            1        0.234386\n",
       "674       zachary levi      1.00            1        0.234386\n",
       "675  zack galifianakis      1.00            1        0.234386\n",
       "676        zack snyder      1.00            1        0.234386\n",
       "\n",
       "[677 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bias Evaluation - Entity-Level Skew \n",
    "\n",
    "# Ensure 'entities' column exists\n",
    "def combine_entities(row):\n",
    "    actors = row.get(\"actors\", [])\n",
    "    directors = row.get(\"directors\", [])\n",
    "    return actors + directors\n",
    "\n",
    "# Ensure columns are lists, not strings\n",
    "import ast\n",
    "for col in ['actors', 'directors']:\n",
    "    test_df[col] = test_df[col].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "test_df['entities'] = test_df.apply(combine_entities, axis=1)\n",
    "\n",
    "# Build entity-level DataFrame\n",
    "test_df['sentiment'] = preds\n",
    "\n",
    "entity_rows = []\n",
    "for _, row in test_df.iterrows():\n",
    "    if not row['entities']:\n",
    "        continue\n",
    "    for entity in row['entities']:\n",
    "        entity_rows.append({'entity': entity, 'sentiment': row['sentiment']})\n",
    "\n",
    "df_entities = pd.DataFrame(entity_rows)\n",
    "\n",
    "\n",
    "# Global positive rate\n",
    "global_pos_rate = df_entities['sentiment'].mean()\n",
    "\n",
    "\n",
    "# Entity-level stats\n",
    "entity_stats = (\n",
    "    df_entities\n",
    "    .groupby('entity')['sentiment']\n",
    "    .agg(['mean','count'])\n",
    "    .reset_index()\n",
    ")\n",
    "entity_stats.rename(columns={'mean':'pos_rate','count':'num_reviews'}, inplace=True)\n",
    "entity_stats['sentiment_skew'] = entity_stats['pos_rate'] - global_pos_rate\n",
    "\n",
    "entity_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
