{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-19T04:31:54.963091Z",
     "start_time": "2025-11-19T04:31:42.886988Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "from  datasets import load_dataset\n",
    "dataset = load_dataset(\"stanfordnlp/imdb\")  \n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "\n",
    "train_data[0]\n",
    "# test_data[0]\n",
    "# print(test_data[0])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\PycharmProjects\\Nlp-final-project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "852a0c5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:46:12.555533Z",
     "start_time": "2025-11-19T04:32:33.935328Z"
    }
   },
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "import spacy\n",
    "\n",
    "# ------------------------------\n",
    "# Load API key and spaCy model\n",
    "# ------------------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.themoviedb.org/3\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # NER model\n",
    "\n",
    "# ------------------------------\n",
    "# Normalize text function\n",
    "# ------------------------------\n",
    "def normalize_text(text):\n",
    "    return unicodedata.normalize(\"NFKC\", text).lower()\n",
    "\n",
    "# ------------------------------\n",
    "# Movie titles\n",
    "# ------------------------------\n",
    "sample_titles = [\n",
    "   \"The Shawshank Redemption\", \"The Godfather\", \"The Dark Knight\", \"Pulp Fiction\", \"Forrest Gump\",\n",
    "    \"Fight Club\", \"Inception\", \"The Matrix\", \"Goodfellas\", \"The Lord of the Rings: The Return of the King\",\n",
    "    \"Interstellar\", \"Parasite\", \"The Silence of the Lambs\", \"Saving Private Ryan\", \"Schindler’s List\",\n",
    "    \"Gladiator\", \"Titanic\", \"The Green Mile\", \"The Departed\", \"Django Unchained\",\n",
    "    \"The Prestige\", \"Whiplash\", \"The Lion King\", \"Toy Story\", \"Avengers: Endgame\",\n",
    "    \"Avengers: Infinity War\", \"Iron Man\", \"Black Panther\", \"Joker\", \"The Social Network\",\n",
    "    \"The Wolf of Wall Street\", \"La La Land\", \"Mad Max: Fury Road\", \"The Revenant\", \"Get Out\",\n",
    "    \"Oppenheimer\", \"Barbie\", \"Dune\", \"The Batman\", \"Spider-Man: No Way Home\",\n",
    "    \"Everything Everywhere All at Once\", \"The Irishman\", \"12 Years a Slave\", \"Moonlight\", \"Spotlight\",\n",
    "    \"Birdman\", \"Arrival\", \"Blade Runner 2049\", \"No Country for Old Men\", \"The Big Short\",\n",
    "    \"The Hateful Eight\", \"Once Upon a Time in Hollywood\", \"There Will Be Blood\",\n",
    "    \"The Curious Case of Benjamin Button\", \"The Shape of Water\", \"The Theory of Everything\",\n",
    "    \"Bohemian Rhapsody\", \"Rocketman\", \"A Star Is Born\", \"The Imitation Game\", \"The King's Speech\",\n",
    "    \"Slumdog Millionaire\", \"Life of Pi\", \"Gravity\", \"Cast Away\", \"The Truman Show\",\n",
    "    \"Eternal Sunshine of the Spotless Mind\", \"Requiem for a Dream\", \"American Beauty\", \"The Sixth Sense\",\n",
    "    \"Se7en\", \"The Usual Suspects\", \"Memento\", \"Oldboy\", \"Pan’s Labyrinth\",\n",
    "    \"Amélie\", \"The Pianist\", \"The Lives of Others\", \"City of God\", \"Crouching Tiger, Hidden Dragon\",\n",
    "    \"Spirited Away\", \"Howl’s Moving Castle\", \"Princess Mononoke\", \"My Neighbor Totoro\", \"WALL·E\",\n",
    "    \"Up\", \"Inside Out\", \"Coco\", \"Soul\", \"Minari\", \"The Banshees of Inisherin\",\n",
    "    \"Casino Royale\", \"South Park: Bigger, Longer & Uncut\", \"A Fistful of Dollars\", \"Rosemary's Baby\",\n",
    "    \"The Incredibles\", \"Black Swan\", \"Deadpool\", \"The Breakfast Club\", \"The Untouchables\",\n",
    "    \"Shaun of the Dead\", \"True Romance\", \"Harry Potter and the Prisoner of Azkaban\", \"Hot Fuzz\",\n",
    "    \"In Bruges\", \"Boyhood\", \"Straight Outta Compton\", \"Drive\", \"Moneyball\", \"Brazil\", \"Chronicle\",\n",
    "    \"Still Alice\", \"Triangle\", \"The Endless\", \"The Man from Earth\",\n",
    "    \"The Secret in Their Eyes\", \"The Fall\", \"The Hunt\", \"Incendies\", \"The Intouchables\",\n",
    "    \"Prisoners\", \"Enemy\", \"Locke\", \"The Lobster\", \"Under the Skin\",\n",
    "    \"Ex Machina\", \"Annihilation\", \"The Florida Project\", \"Room\", \"Brooklyn\",\n",
    "    \"Carol\", \"The Farewell\", \"Portrait of a Lady on Fire\", \"The Handmaiden\", \"Shoplifters\",\n",
    "    \"A Separation\", \"Toni Erdmann\", \"Cold War\", \"Wild Tales\", \"The Square\"\n",
    "]\n",
    "\n",
    "# normalize titles for regex patterns\n",
    "sample_titles_norm = [normalize_text(t) for t in sample_titles]\n",
    "\n",
    "title_patterns = {\n",
    "    title: re.compile(r\"(?<!\\w)\" + re.escape(title) + r\"(?!\\w)\", re.IGNORECASE)\n",
    "    for title in sample_titles_norm\n",
    "}\n",
    "\n",
    "# ------------------------------\n",
    "# Detect titles function\n",
    "# ------------------------------\n",
    "def detect_titles_regex(text, patterns):\n",
    "    text_norm = normalize_text(text)\n",
    "    detected = []\n",
    "    for title, pattern in patterns.items():\n",
    "        if pattern.search(text_norm):\n",
    "            detected.append(title)\n",
    "    return detected\n",
    "\n",
    "# ------------------------------\n",
    "# TMDb metadata caching\n",
    "# ------------------------------\n",
    "metadata_cache = {}\n",
    "\n",
    "def get_movie_metadata(title):\n",
    "    title_key = title.strip().lower()\n",
    "    if title_key in metadata_cache:\n",
    "        return metadata_cache[title_key]\n",
    "\n",
    "    query_title = title.strip().title()  # proper case for API\n",
    "    search_url = f\"{BASE_URL}/search/movie?api_key={API_KEY}&query={query_title}\"\n",
    "    try:\n",
    "        search_response = requests.get(search_url).json()\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "    if not search_response.get(\"results\"):\n",
    "        return None\n",
    "\n",
    "    movie_id = search_response[\"results\"][0][\"id\"]\n",
    "\n",
    "    credits_url = f\"{BASE_URL}/movie/{movie_id}/credits?api_key={API_KEY}\"\n",
    "    try:\n",
    "        credits_response = requests.get(credits_url).json()\n",
    "    except requests.RequestException:\n",
    "        return None\n",
    "\n",
    "    actors = [member[\"name\"] for member in credits_response.get(\"cast\", [])[:7]]\n",
    "    directors = [member[\"name\"] for member in credits_response.get(\"crew\", []) if member[\"job\"] == \"Director\"]\n",
    "\n",
    "    result = {\"actors\": actors, \"directors\": directors}\n",
    "    metadata_cache[title_key] = result\n",
    "    sleep(0.25)  # rate limit\n",
    "    return result\n",
    "\n",
    "# ------------------------------\n",
    "# Enrich with metadata\n",
    "# ------------------------------\n",
    "def enrich_with_metadata(row):\n",
    "    titles = row.get(\"detected_titles\", [])\n",
    "    if not titles:\n",
    "        row[\"actors\"] = None\n",
    "        row[\"directors\"] = None\n",
    "        row[\"ner_entities\"] = []\n",
    "        return row\n",
    "\n",
    "    metadata = get_movie_metadata(titles[0])\n",
    "    row[\"actors\"] = metadata.get(\"actors\") if metadata else []\n",
    "    row[\"directors\"] = metadata.get(\"directors\") if metadata else []\n",
    "\n",
    "    # ------------------------------\n",
    "    # Use spaCy NER to detect persons in review\n",
    "    # ------------------------------\n",
    "    doc = nlp(row[\"text\"])\n",
    "    persons_in_review = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "    # ------------------------------\n",
    "    # Link detected persons to movie metadata\n",
    "    # ------------------------------\n",
    "    relevant_entities = []\n",
    "    for person in persons_in_review:\n",
    "        if person in row[\"actors\"] or person in row[\"directors\"]:\n",
    "            relevant_entities.append(person)\n",
    "\n",
    "    row[\"ner_entities\"] = relevant_entities\n",
    "    return row\n",
    "\n",
    "# ------------------------------\n",
    "# Load dataset\n",
    "# ------------------------------\n",
    "train_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Detect titles\n",
    "train_df[\"detected_titles\"] = train_df[\"text\"].apply(lambda x: detect_titles_regex(x, title_patterns))\n",
    "\n",
    "# Filter rows with at least one detected title\n",
    "matched_reviews = train_df[train_df[\"detected_titles\"].map(len) > 0].copy()\n",
    "\n",
    "# Initialize columns\n",
    "matched_reviews[\"actors\"] = None\n",
    "matched_reviews[\"directors\"] = None\n",
    "matched_reviews[\"ner_entities\"] = None\n",
    "\n",
    "# Enrich with metadata and NER\n",
    "matched_reviews = matched_reviews.apply(enrich_with_metadata, axis=1)\n",
    "\n",
    "# ------------------------------\n",
    "# Save final DataFrame - for development purposes\n",
    "# ------------------------------\n",
    "matched_reviews.to_csv(\"matched_reviews_with_metadata_ner.csv\", index=False)\n",
    "print(\"Pipeline complete. Saved matched reviews with NER metadata.\")\n",
    "\n",
    "#Took about 38 minutes to run the full pipeline on the training set.\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline complete. Saved matched reviews with NER metadata.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T05:17:30.122240Z",
     "start_time": "2025-11-19T05:17:30.101460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mask = matched_reviews[\"detected_titles\"] =='the endless'\n",
    "mask"
   ],
   "id": "2404fef39e00aabc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2        False\n",
       "3        False\n",
       "8        False\n",
       "10       False\n",
       "14       False\n",
       "         ...  \n",
       "24991    False\n",
       "24995    False\n",
       "24996    False\n",
       "24997    False\n",
       "24998    False\n",
       "Name: detected_titles, Length: 10413, dtype: bool"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "id": "576a8f7600880056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:01.460704Z",
     "start_time": "2025-11-19T04:46:52.322221Z"
    }
   },
   "source": [
    "# Baseline Classification Models without NER Metadata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Prepare data for modeling\n",
    "df = matched_reviews.copy()\n",
    "\n",
    "# Ensure text is string\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]     # 0 = negative, 1 = positive\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20_000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "6a4afe24c4746605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:06.284234Z",
     "start_time": "2025-11-19T04:47:06.123506Z"
    }
   },
   "source": [
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_lr = log_reg.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_lr))\n",
    "print(classification_report(y_test, pred_lr))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Logistic Regression ====\n",
      "Accuracy: 0.8694191070571291\n",
      "F1 Score: 0.8698564593301435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      1064\n",
      "           1       0.85      0.89      0.87      1019\n",
      "\n",
      "    accuracy                           0.87      2083\n",
      "   macro avg       0.87      0.87      0.87      2083\n",
      "weighted avg       0.87      0.87      0.87      2083\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b097d143e22dde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:13.753215Z",
     "start_time": "2025-11-19T04:47:13.634564Z"
    }
   },
   "source": [
    "# SVM Model\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_svm = svm_clf.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Linear SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Linear SVM ====\n",
      "Accuracy: 0.8684589534325492\n",
      "F1 Score: 0.8676328502415459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1064\n",
      "           1       0.85      0.88      0.87      1019\n",
      "\n",
      "    accuracy                           0.87      2083\n",
      "   macro avg       0.87      0.87      0.87      2083\n",
      "weighted avg       0.87      0.87      0.87      2083\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "10057214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:30.159859Z",
     "start_time": "2025-11-19T04:47:25.355144Z"
    }
   },
   "source": [
    "# Baseline Classification Models with NER Metadata\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "def compute_entity_features(row):\n",
    "    titles = row[\"detected_titles\"]\n",
    "\n",
    "    # actors/directors are lists, not strings\n",
    "    actors = row.get(\"actors\", [])\n",
    "    directors = row.get(\"directors\", [])\n",
    "\n",
    "    num_titles = len(titles)\n",
    "    num_actors = len(actors)\n",
    "    num_directors = len(directors)\n",
    "\n",
    "    text = row[\"text\"].lower()\n",
    "\n",
    "    # Count actor mentions\n",
    "    actor_mentions = 0\n",
    "    for a in actors:\n",
    "        actor_mentions += text.count(a.lower())\n",
    "\n",
    "    # Count director mentions\n",
    "    director_mentions = 0\n",
    "    for d in directors:\n",
    "        director_mentions += text.count(d.lower())\n",
    "\n",
    "    # Sentiment toward entity names\n",
    "    entity_tokens = actors + directors\n",
    "    entity_sentiment = 0\n",
    "\n",
    "    if entity_tokens:\n",
    "        combined = \" \".join(entity_tokens)\n",
    "        try:\n",
    "            entity_sentiment = TextBlob(combined).sentiment.polarity\n",
    "        except:\n",
    "            entity_sentiment = 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"num_titles\": num_titles,\n",
    "        \"num_actors\": num_actors,\n",
    "        \"num_directors\": num_directors,\n",
    "        \"actor_mentions\": actor_mentions,\n",
    "        \"director_mentions\": director_mentions,\n",
    "        \"entity_sentiment\": entity_sentiment\n",
    "    })\n",
    "\n",
    "\n",
    "# Compute entity features\n",
    "entity_features = matched_reviews.apply(compute_entity_features, axis=1)\n",
    "full_df = pd.concat([matched_reviews, entity_features], axis=1)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "3fd9c56a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:48.932274Z",
     "start_time": "2025-11-19T04:47:40.921747Z"
    }
   },
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# TF-IDF Vectorization on review text with NER features\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_text = tfidf.fit_transform(full_df[\"text\"])\n",
    "\n",
    "# Combine text features with NER features\n",
    "X_entity = full_df[[\n",
    "    \"num_titles\", \"num_actors\", \"num_directors\",\n",
    "    \"actor_mentions\", \"director_mentions\",\n",
    "    \"entity_sentiment\"\n",
    "]].fillna(0).values\n",
    "\n",
    "X = hstack([X_text, X_entity])\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "b4b9b511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:47:57.039385Z",
     "start_time": "2025-11-19T04:47:56.078349Z"
    }
   },
   "source": [
    "# Logistic Regression with NER features\n",
    "log_clf = LogisticRegression(max_iter=500)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_log))\n",
    "print(classification_report(y_test, pred_log))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware Logistic Regression ====\n",
      "Accuracy: 0.8665386461833894\n",
      "F1 Score: 0.8635917566241413\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      1086\n",
      "           1       0.85      0.88      0.86       997\n",
      "\n",
      "    accuracy                           0.87      2083\n",
      "   macro avg       0.87      0.87      0.87      2083\n",
      "weighted avg       0.87      0.87      0.87      2083\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8e89465c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T04:48:01.485466Z",
     "start_time": "2025-11-19T04:48:01.060267Z"
    }
   },
   "source": [
    "# SVM with NER features\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware SVM ====\n",
      "Accuracy: 0.8679788766202592\n",
      "F1 Score: 0.8645987198424422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87      1086\n",
      "           1       0.85      0.88      0.86       997\n",
      "\n",
      "    accuracy                           0.87      2083\n",
      "   macro avg       0.87      0.87      0.87      2083\n",
      "weighted avg       0.87      0.87      0.87      2083\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
