{
 "cells": [
  {
   "cell_type": "code",
   "id": "7a07fd19ef67c22c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:34:36.070910Z",
     "start_time": "2025-11-25T03:34:30.112905Z"
    }
   },
   "source": [
    "# load matched reviews\n",
    "import pandas as pd\n",
    "matched_reviews = pd.read_csv(\"matched_reviews_with_metadata_ner.csv\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "576a8f7600880056",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:16:55.453620Z",
     "start_time": "2025-11-25T02:16:47.711861Z"
    }
   },
   "source": [
    "# Baseline Classification Models without NER Metadata\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "\n",
    "# Prepare data for modeling\n",
    "df = matched_reviews.copy()\n",
    "\n",
    "# Ensure text is string\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]     # 0 = negative, 1 = positive\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=20_000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "6a4afe24c4746605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:17:01.202990Z",
     "start_time": "2025-11-25T02:17:01.083530Z"
    }
   },
   "source": [
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=500)\n",
    "log_reg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_lr = log_reg.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_lr))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_lr))\n",
    "print(classification_report(y_test, pred_lr))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Logistic Regression ====\n",
      "Accuracy: 0.8712465878070974\n",
      "F1 Score: 0.8700045934772623\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1122\n",
      "           1       0.86      0.88      0.87      1076\n",
      "\n",
      "    accuracy                           0.87      2198\n",
      "   macro avg       0.87      0.87      0.87      2198\n",
      "weighted avg       0.87      0.87      0.87      2198\n",
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b097d143e22dde5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:17:12.004589Z",
     "start_time": "2025-11-25T02:17:11.870157Z"
    }
   },
   "source": [
    "# SVM Model\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Evaluation\n",
    "pred_svm = svm_clf.predict(X_test_vec)\n",
    "\n",
    "print(\"==== Linear SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Linear SVM ====\n",
      "Accuracy: 0.8689717925386715\n",
      "F1 Score: 0.8675252989880404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      1122\n",
      "           1       0.86      0.88      0.87      1076\n",
      "\n",
      "    accuracy                           0.87      2198\n",
      "   macro avg       0.87      0.87      0.87      2198\n",
      "weighted avg       0.87      0.87      0.87      2198\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "10057214",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:18:22.601277Z",
     "start_time": "2025-11-25T02:18:12.638838Z"
    }
   },
   "source": [
    "# Baseline Classification Models with NER Metadata\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "def compute_entity_features(row):\n",
    "    titles = row[\"detected_titles\"]\n",
    "\n",
    "    # actors/directors are lists, not strings\n",
    "    actors = row.get(\"actors\", [])\n",
    "    directors = row.get(\"directors\", [])\n",
    "\n",
    "    num_titles = len(titles)\n",
    "    num_actors = len(actors)\n",
    "    num_directors = len(directors)\n",
    "\n",
    "    text = row[\"text\"].lower()\n",
    "\n",
    "    # Count actor mentions\n",
    "    actor_mentions = 0\n",
    "    for a in actors:\n",
    "        actor_mentions += text.count(a.lower())\n",
    "\n",
    "    # Count director mentions\n",
    "    director_mentions = 0\n",
    "    for d in directors:\n",
    "        director_mentions += text.count(d.lower())\n",
    "\n",
    "    # Sentiment toward entity names\n",
    "    entity_tokens = actors + directors\n",
    "    entity_sentiment = 0\n",
    "\n",
    "    if entity_tokens:\n",
    "        combined = \" \".join(entity_tokens)\n",
    "        try:\n",
    "            entity_sentiment = TextBlob(combined).sentiment.polarity\n",
    "        except:\n",
    "            entity_sentiment = 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"num_titles\": num_titles,\n",
    "        \"num_actors\": num_actors,\n",
    "        \"num_directors\": num_directors,\n",
    "        \"actor_mentions\": actor_mentions,\n",
    "        \"director_mentions\": director_mentions,\n",
    "        \"entity_sentiment\": entity_sentiment\n",
    "    })\n",
    "\n",
    "\n",
    "# Compute entity features\n",
    "entity_features = matched_reviews.apply(compute_entity_features, axis=1)\n",
    "full_df = pd.concat([matched_reviews, entity_features], axis=1)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c021aeaf1246e003",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:18:34.407847Z",
     "start_time": "2025-11-25T02:18:26.162867Z"
    }
   },
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split BEFORE vectorization\n",
    "X_text_raw = full_df[\"text\"]\n",
    "X_entity = full_df[[\n",
    "    \"num_titles\", \"num_actors\", \"num_directors\",\n",
    "    \"actor_mentions\", \"director_mentions\",\n",
    "    \"entity_sentiment\"\n",
    "]].fillna(0).values\n",
    "y = full_df[\"label\"]\n",
    "\n",
    "# Train-test split on raw data\n",
    "X_text_train, X_text_test, X_entity_train, X_entity_test, y_train, y_test = train_test_split(\n",
    "    X_text_raw, X_entity, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Now fit TF-IDF only on training text\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "X_train_text = tfidf.fit_transform(X_text_train)  # Learn from train only\n",
    "X_test_text = tfidf.transform(X_text_test)        # Apply to test\n",
    "\n",
    "# Scale entity features (fit on train, transform both)\n",
    "scaler = StandardScaler(with_mean=False)  # Sparse-compatible\n",
    "X_entity_train_scaled = scaler.fit_transform(X_entity_train)\n",
    "X_entity_test_scaled = scaler.transform(X_entity_test)\n",
    "\n",
    "# Combine features\n",
    "X_train = hstack([X_train_text, X_entity_train])\n",
    "X_test = hstack([X_test_text, X_entity_test])"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "b4b9b511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:18:40.984483Z",
     "start_time": "2025-11-25T02:18:37.249206Z"
    }
   },
   "source": [
    "# Logistic Regression with NER features\n",
    "log_clf = LogisticRegression(max_iter=500)\n",
    "log_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_log = log_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware Logistic Regression ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_log))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_log))\n",
    "print(classification_report(y_test, pred_log))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware Logistic Regression ====\n",
      "Accuracy: 0.8516833484986351\n",
      "F1 Score: 0.8473782771535581\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86      1122\n",
      "           1       0.85      0.84      0.85      1076\n",
      "\n",
      "    accuracy                           0.85      2198\n",
      "   macro avg       0.85      0.85      0.85      2198\n",
      "weighted avg       0.85      0.85      0.85      2198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 500 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=500).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8e89465c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:18:54.572131Z",
     "start_time": "2025-11-25T02:18:53.180562Z"
    }
   },
   "source": [
    "# SVM with NER features\n",
    "svm_clf = LinearSVC()\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "pred_svm = svm_clf.predict(X_test)\n",
    "\n",
    "print(\"==== Entity-Aware SVM ====\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, pred_svm))\n",
    "print(\"F1 Score:\", f1_score(y_test, pred_svm))\n",
    "print(classification_report(y_test, pred_svm))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Entity-Aware SVM ====\n",
      "Accuracy: 0.873066424021838\n",
      "F1 Score: 0.869198312236287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1122\n",
      "           1       0.88      0.86      0.87      1076\n",
      "\n",
      "    accuracy                           0.87      2198\n",
      "   macro avg       0.87      0.87      0.87      2198\n",
      "weighted avg       0.87      0.87      0.87      2198\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "d86bcd99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:28:42.694288Z",
     "start_time": "2025-11-25T02:28:42.664905Z"
    }
   },
   "source": [
    "# prepare data for modeling\n",
    "df = full_df[[\"text\", \"label\"]].dropna()\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[\"label\"])"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "77b1f528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:28:49.500781Z",
     "start_time": "2025-11-25T02:28:49.037770Z"
    }
   },
   "source": [
    "# Tokenization with DistilBERT tokenizer\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\",\n",
    "                                                     use_fast=True,\n",
    "                                                    local_files_only=False\n",
    "                                                    )     \n",
    "\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "f1575086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:28:56.475949Z",
     "start_time": "2025-11-25T02:28:53.101326Z"
    }
   },
   "source": [
    "# Convert to Hugging Face Datasets because transformers work well with them instead of dataframes\n",
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "train_ds = train_ds.map(tokenize_batch, batched=True)\n",
    "test_ds = test_ds.map(tokenize_batch, batched=True)\n",
    "\n",
    "train_ds = train_ds.rename_column(\"label\", \"labels\")\n",
    "test_ds = test_ds.rename_column(\"label\", \"labels\")\n",
    "\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 8792/8792 [00:02<00:00, 3552.09 examples/s]\n",
      "Map: 100%|██████████| 2198/2198 [00:00<00:00, 3067.89 examples/s]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "3239a1e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:29:04.315531Z",
     "start_time": "2025-11-25T02:29:03.978380Z"
    }
   },
   "source": [
    "# Load DistilBERT model \n",
    "num_labels = df[\"label\"].nunique()\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=num_labels\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "acd96fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:29:21.117109Z",
     "start_time": "2025-11-25T02:29:21.111024Z"
    }
   },
   "source": [
    "# import torch\n",
    "# import accelerate # Accelerate must be 0.33.0\n",
    "# import transformers\n",
    "\n",
    "# print(torch.__version__)\n",
    "# print(accelerate.__version__)\n",
    "# print(transformers.__version__)\n",
    "\n",
    "# import sys\n",
    "# print(sys.executable)\n",
    "# print(sys.path)\n",
    "\n",
    "# import importlib\n",
    "# import transformers\n",
    "# import accelerate\n",
    "\n",
    "# importlib.reload(transformers)\n",
    "# importlib.reload(accelerate)\n",
    "\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import transformers, accelerate\n",
    "print(transformers.__version__)\n",
    "print(accelerate.__version__)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Python314\\python.exe\n",
      "4.57.2\n",
      "1.12.0\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "96b1fc7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:29:32.888862Z",
     "start_time": "2025-11-25T02:29:32.719460Z"
    }
   },
   "source": [
    "# Training with Hugging Face Trainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./distilbert-sentiment\",\n",
    "    \n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    \n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "\n",
    "    logging_steps=50,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=test_ds,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "1ac06753",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-25T02:29:38.779908Z"
    }
   },
   "source": [
    "trainer.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\charl\\AppData\\Roaming\\Python\\Python314\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9/550 00:42 < 54:08, 0.17 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": "cede5bb8ee83a931bcd0957c53a3a637"
     }
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8142211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\charl\\projects\\nlp\\Nlp-Final-Fall-2025\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5090044140815735,\n",
       " 'eval_runtime': 192.6551,\n",
       " 'eval_samples_per_second': 10.771,\n",
       " 'eval_steps_per_second': 0.675,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d705087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions_output = trainer.predict(test_ds)  # test_ds is your HF Dataset\n",
    "\n",
    "# predictions_output is a PredictionOutput object\n",
    "logits = predictions_output.predictions  # raw model outputs\n",
    "labels = predictions_output.label_ids   # true labels\n",
    "\n",
    "# Convert logits to predicted class indices\n",
    "preds = np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57fddb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== DistilBERT Evaluation ====\n",
      "Accuracy: 0.8790361445783132\n",
      "F1 Score: 0.8790490691928209\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88      1059\n",
      "           1       0.87      0.89      0.88      1016\n",
      "\n",
      "    accuracy                           0.88      2075\n",
      "   macro avg       0.88      0.88      0.88      2075\n",
      "weighted avg       0.88      0.88      0.88      2075\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds, average='weighted')  # or 'macro' if you prefer\n",
    "\n",
    "print(\"==== DistilBERT Evaluation ====\")\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb2a9524f7197fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T17:28:37.375185Z",
     "start_time": "2025-11-21T17:28:37.353776Z"
    }
   },
   "outputs": [],
   "source": [
    "# # DistilBERT Model for Sentiment Classification\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "# from torch.optim import AdamW\n",
    "# from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "#\n",
    "# # Check for GPU\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Custom Dataset Class\n",
    "# # ------------------------------\n",
    "# class ReviewDataset(Dataset):\n",
    "#     def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "#         self.texts = texts\n",
    "#         self.labels = labels\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "#\n",
    "#     def __getitem__(self, idx):\n",
    "#         text = str(self.texts.iloc[idx])\n",
    "#         label = self.labels.iloc[idx]\n",
    "#\n",
    "#         encoding = self.tokenizer.encode_plus(\n",
    "#             text,\n",
    "#             add_special_tokens=True,\n",
    "#             max_length=self.max_length,\n",
    "#             padding='max_length',\n",
    "#             truncation=True,\n",
    "#             return_attention_mask=True,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "#\n",
    "#         return {\n",
    "#             'input_ids': encoding['input_ids'].flatten(),\n",
    "#             'attention_mask': encoding['attention_mask'].flatten(),\n",
    "#             'label': torch.tensor(label, dtype=torch.long)\n",
    "#         }\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Prepare data\n",
    "# # ------------------------------\n",
    "# # Use the same train-test split as before\n",
    "# X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "#     full_df[\"text\"], full_df[\"label\"],\n",
    "#     test_size=0.2,\n",
    "#     random_state=42,\n",
    "#     stratify=full_df[\"label\"]\n",
    "# )\n",
    "#\n",
    "# # Initialize tokenizer\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "#\n",
    "# # Create datasets\n",
    "# train_dataset = ReviewDataset(X_train_text, y_train, tokenizer)\n",
    "# test_dataset = ReviewDataset(X_test_text, y_test, tokenizer)\n",
    "#\n",
    "# # Create dataloaders\n",
    "# batch_size = 16\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Initialize Model\n",
    "# # ------------------------------\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\n",
    "#     'distilbert-base-uncased',\n",
    "#     num_labels=2  # binary classification\n",
    "# )\n",
    "# model.to(device)\n",
    "#\n",
    "# # Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Training Function\n",
    "# # ------------------------------\n",
    "# def train_epoch(model, dataloader, optimizer, device):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#\n",
    "#     for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "#         optimizer.zero_grad()\n",
    "#\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "#\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels\n",
    "#         )\n",
    "#\n",
    "#         loss = outputs.loss\n",
    "#         total_loss += loss.item()\n",
    "#\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#\n",
    "#     return total_loss / len(dataloader)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Evaluation Function\n",
    "# # ------------------------------\n",
    "# def evaluate(model, dataloader, device):\n",
    "#     model.eval()\n",
    "#     predictions = []\n",
    "#     true_labels = []\n",
    "#\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch['input_ids'].to(device)\n",
    "#             attention_mask = batch['attention_mask'].to(device)\n",
    "#             labels = batch['label'].to(device)\n",
    "#\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask\n",
    "#             )\n",
    "#\n",
    "#             logits = outputs.logits\n",
    "#             preds = torch.argmax(logits, dim=1)\n",
    "#\n",
    "#             predictions.extend(preds.cpu().numpy())\n",
    "#             true_labels.extend(labels.cpu().numpy())\n",
    "#\n",
    "#     return np.array(predictions), np.array(true_labels)\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Train the Model\n",
    "# # ------------------------------\n",
    "# num_epochs = 3\n",
    "#\n",
    "# print(\"Starting training...\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "#\n",
    "#     train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "#     print(f\"Average training loss: {train_loss:.4f}\")\n",
    "#\n",
    "#     # Evaluate on test set after each epoch\n",
    "#     predictions, true_labels = evaluate(model, test_loader, device)\n",
    "#     accuracy = accuracy_score(true_labels, predictions)\n",
    "#     f1 = f1_score(true_labels, predictions)\n",
    "#\n",
    "#     print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "#     print(f\"Test F1 Score: {f1:.4f}\")\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Final Evaluation\n",
    "# # ------------------------------\n",
    "# print(\"\\n==== DistilBERT Final Results ====\")\n",
    "# predictions, true_labels = evaluate(model, test_loader, device)\n",
    "#\n",
    "# print(\"Accuracy:\", accuracy_score(true_labels, predictions))\n",
    "# print(\"F1 Score:\", f1_score(true_labels, predictions))\n",
    "# print(classification_report(true_labels, predictions))\n",
    "#\n",
    "# # ------------------------------\n",
    "# # Save model (optional)\n",
    "# # ------------------------------\n",
    "# model.save_pretrained(\"./distilbert_sentiment_model\")\n",
    "# tokenizer.save_pretrained(\"./distilbert_sentiment_model\")\n",
    "# print(\"\\nModel saved to ./distilbert_sentiment_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796bb35475a1b6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-11-21T17:28:37.454293Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading TinyBERT model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at huawei-noah/TinyBERT_General_4L_312D and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "Starting training...\n",
      "Training samples: 8297\n",
      "Test samples: 2075\n",
      "Batch size: 32\n",
      "Epochs: 2\n",
      "\n",
      "\n",
      "==================================================\n",
      "Epoch 1/2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  74%|███████▍  | 192/260 [18:03<09:10,  8.10s/it]"
     ]
    }
   ],
   "source": [
    "# TinyBERT Model for Sentiment Classification\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Custom Dataset Class\n",
    "# ------------------------------\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# ------------------------------\n",
    "# Prepare data\n",
    "# ------------------------------\n",
    "# Use the same train-test split as before\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    full_df[\"text\"], full_df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Initialize TinyBERT tokenizer and model\n",
    "print(\"Loading TinyBERT model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('huawei-noah/TinyBERT_General_4L_312D')\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'huawei-noah/TinyBERT_General_4L_312D',\n",
    "    num_labels=2\n",
    ")\n",
    "model.to(device)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Create datasets (using max_length=256 for faster training)\n",
    "train_dataset = ReviewDataset(X_train_text, y_train, tokenizer, max_length=256)\n",
    "test_dataset = ReviewDataset(X_test_text, y_test, tokenizer, max_length=256)\n",
    "\n",
    "# Create dataloaders (increased batch size for speed)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# ------------------------------\n",
    "# Training Function\n",
    "# ------------------------------\n",
    "def train_epoch(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# ------------------------------\n",
    "# Evaluation Function\n",
    "# ------------------------------\n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(true_labels)\n",
    "\n",
    "# ------------------------------\n",
    "# Train the Model\n",
    "# ------------------------------\n",
    "num_epochs = 2  # Reduced to 2 for faster training\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Epochs: {num_epochs}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print('='*50)\n",
    "\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    print(f\"Average training loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate on test set after each epoch\n",
    "    predictions, true_labels = evaluate(model, test_loader, device)\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Final Evaluation\n",
    "# ------------------------------\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"==== TinyBERT Final Results ====\")\n",
    "print(\"=\"*50)\n",
    "predictions, true_labels = evaluate(model, test_loader, device)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "f1 = f1_score(true_labels, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=['Negative', 'Positive']))\n",
    "\n",
    "# ------------------------------\n",
    "# Save model (optional)\n",
    "# ------------------------------\n",
    "save_model = input(\"\\nSave model? (y/n): \").lower()\n",
    "if save_model == 'y':\n",
    "    model.save_pretrained(\"./tinybert_sentiment_model\")\n",
    "    tokenizer.save_pretrained(\"./tinybert_sentiment_model\")\n",
    "    print(\"Model saved to ./tinybert_sentiment_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
